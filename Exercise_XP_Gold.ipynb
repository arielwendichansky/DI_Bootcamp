{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODOJdmkJWN//3Zv4TR8pq8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arielwendichansky/DI_Bootcamp/blob/master/Exercise_XP_Gold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1 : Export A Dataframe To JSON With Orient"
      ],
      "metadata": {
        "id": "6o9e1GjsoqXi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n6ZU8HjhGp5m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "vX5wiRdDGxi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "IiX5KZmsHSdl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "'UserID': range(1, 11),\n",
        "'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma',\n",
        "         'Frank', 'Grace', 'Hannah', 'Ian', 'Jane'],\n",
        "'Age': [25, 30, 35, 40, 29, 34, 28, 31, 36, 33],\n",
        "'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix',\n",
        "         'Philadelphia', 'San Antonio', 'San Diego', 'Dallas', 'San Jose']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "hsik0heZHe2C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_json('data.json', orient = 'columns')"
      ],
      "metadata": {
        "id": "IsOYRZLWJCpv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2: Export A Dataframe From Excel\n"
      ],
      "metadata": {
        "id": "MNY-En4gJu5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame({\n",
        "'Date': pd.date_range('20210101', periods=20),\n",
        "'Product': ['Product A', 'Product B', 'Product C'] * 6 + ['Product A', 'Product B'],\n",
        "'Quantity': [2, 3, 5, 7, 1] * 4,\n",
        "'Revenue': [210.50, 340.60, 450.30, 120.10, 150.75] * 4\n",
        "})\n",
        "\n",
        "data.to_excel('data2.xlsx', index=False)"
      ],
      "metadata": {
        "id": "RGeESCwMJiuL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_excel('data2.xlsx')\n",
        "df1"
      ],
      "metadata": {
        "id": "3WRkVoMKKZCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = pd.DataFrame({\n",
        "'Stock': ['In stock'] *19\n",
        "})\n",
        "new_df = pd.DataFrame(new_data)\n",
        "df1 = pd.concat([df1, new_df], ignore_index=True)\n",
        "with pd.ExcelWriter('data2.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "    df1.to_excel(writer, index=False, sheet_name='Sheet2', startrow=0, startcol=0)"
      ],
      "metadata": {
        "id": "Rl-TS646Lhd2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Revenue\"] = data['Revenue'].astype(int)"
      ],
      "metadata": {
        "id": "yYvWHkaSXEWq"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 3 Chunking Large Datasets"
      ],
      "metadata": {
        "id": "SAs31KPUX5iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d brendan45774/test-file"
      ],
      "metadata": {
        "id": "glZFpkyNYJZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip test-file.zip"
      ],
      "metadata": {
        "id": "6ARhWti8ZtQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunksize = 1000\n",
        "total_survived = 0\n",
        "total_passangers = 0\n",
        "df = pd.read_csv('tested.csv',chunksize=chunksize)\n",
        "for chunk in df:\n",
        "  print(chunk.head(10))\n",
        "  chunk_sum = chunk['Survived'].sum()\n",
        "  total_survived += chunk_sum\n",
        "  chunk_count = chunk['PassengerId'].count()\n",
        "  total_passangers += chunk_count\n",
        "  print(f\"These are the total passangers {total_passangers}\")\n",
        "  print(f\"These are the total surviver {total_survived}\")\n",
        "chunk.to_csv('output_chunk.csv', mode='a')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X78f6dVecrIm",
        "outputId": "81c9730a-2281-44c7-8382-ca2902c3de69"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         1       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         1       3   \n",
            "5          897         0       3   \n",
            "6          898         1       3   \n",
            "7          899         0       2   \n",
            "8          900         1       3   \n",
            "9          901         0       3   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James    male  34.5      0      0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
            "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
            "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
            "5                    Svensson, Mr. Johan Cervin    male  14.0      0      0   \n",
            "6                          Connolly, Miss. Kate  female  30.0      0      0   \n",
            "7                  Caldwell, Mr. Albert Francis    male  26.0      1      1   \n",
            "8     Abrahim, Mrs. Joseph (Sophie Halaut Easu)  female  18.0      0      0   \n",
            "9                       Davies, Mr. John Samuel    male  21.0      2      0   \n",
            "\n",
            "      Ticket     Fare Cabin Embarked  \n",
            "0     330911   7.8292   NaN        Q  \n",
            "1     363272   7.0000   NaN        S  \n",
            "2     240276   9.6875   NaN        Q  \n",
            "3     315154   8.6625   NaN        S  \n",
            "4    3101298  12.2875   NaN        S  \n",
            "5       7538   9.2250   NaN        S  \n",
            "6     330972   7.6292   NaN        Q  \n",
            "7     248738  29.0000   NaN        S  \n",
            "8       2657   7.2292   NaN        C  \n",
            "9  A/4 48871  24.1500   NaN        S  \n",
            "These are the total passangers 418\n",
            "These are the total surviver 152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 4: Using Efficient File Formats\n"
      ],
      "metadata": {
        "id": "JsjbOqQpjy7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyarrow\n"
      ],
      "metadata": {
        "id": "cGNEuuEXlsS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow.parquet as pq\n",
        "\n",
        "df = pd.DataFrame(df)\n",
        "df.to_parquet('large_data.parquet')"
      ],
      "metadata": {
        "id": "PxkIUNKKeOLU"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Get the size of a file\n",
        "file_path = 'large_data.parquet'\n",
        "file_size_bytes = os.path.getsize(file_path)\n",
        "file_size_mb = file_size_bytes / (1024 * 1024)  # Convert bytes to MB\n",
        "\n",
        "print(\"File size:\", file_size_bytes, \"bytes\")\n",
        "print(\"File size:\", file_size_mb, \"MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWdpLxaznIVk",
        "outputId": "8f916ed0-8c81-40f6-f5b3-ac6058db3764"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size: 1388 bytes\n",
            "File size: 0.001323699951171875 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the size of a file\n",
        "file_path = 'tested.csv'\n",
        "file_size_bytes = os.path.getsize(file_path)\n",
        "file_size_mb = file_size_bytes / (1024 * 1024)  # Convert bytes to MB\n",
        "\n",
        "print(\"File size:\", file_size_bytes, \"bytes\")\n",
        "print(\"File size:\", file_size_mb, \"MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBX4pH6LnwAP",
        "outputId": "a1a5c2fe-d239-41aa-ec8e-99330ff8ec54"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size: 29474 bytes\n",
            "File size: 0.028108596801757812 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Measure read speed\n",
        "start_time = time.time()\n",
        "df = pd.read_parquet('large_data.parquet')\n",
        "end_time = time.time()\n",
        "read_time = end_time - start_time\n",
        "print(\"Read time:\", read_time, \"seconds\")\n",
        "\n",
        "# Measure write speed\n",
        "start_time = time.time()\n",
        "df.to_parquet('large_data.parquet')\n",
        "end_time = time.time()\n",
        "write_time = end_time - start_time\n",
        "print(\"Write time:\", write_time, \"seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNV6innRncoR",
        "outputId": "24985b4c-92f3-45ae-8d49-dc4dbf5fef82"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read time: 0.05801105499267578 seconds\n",
            "Write time: 0.0018744468688964844 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Measure read speed\n",
        "start_time = time.time()\n",
        "df = pd.read_csv('tested.csv')\n",
        "end_time = time.time()\n",
        "read_time = end_time - start_time\n",
        "print(\"Read time:\", read_time, \"seconds\")\n",
        "\n",
        "# Measure write speed\n",
        "start_time = time.time()\n",
        "df.to_csv('tested.csv')\n",
        "end_time = time.time()\n",
        "write_time = end_time - start_time\n",
        "print(\"Write time:\", write_time, \"seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gk00kvAn5xh",
        "outputId": "24abcb83-0b80-44ca-b7d1-b14120d5e9b5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read time: 0.007813692092895508 seconds\n",
            "Write time: 0.0044710636138916016 seconds\n"
          ]
        }
      ]
    }
  ]
}
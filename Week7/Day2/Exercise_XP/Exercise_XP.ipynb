{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP25Pgj1y0ewpw4BMnC6oFD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arielwendichansky/DI_Bootcamp/blob/master/Week7/Day2/Exercise_XP/Exercise_XP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install selenium"
      ],
      "metadata": {
        "id": "ES8GPYSI_cJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üåü Exercise 3 : Scrape Dynamic Content From Rotten Tomatoes\n",
        "Task:\n",
        "Use Selenium to navigate to the Rotten Tomatoes Certified Fresh Movies page.\n",
        "Extract the HTML content after it‚Äôs fully loaded.\n",
        "Use BeautifulSoup to parse and extract the movie titles, scores, and release dates.\n",
        "Instructions\n",
        "Set up Selenium WebDriver and navigate to the Rotten Tomatoes page.\n",
        "Extract the HTML content using driver.page_source.\n",
        "Parse the HTML with BeautifulSoup.\n",
        "Find and extract the desired movie information.\n",
        "Print the extracted data"
      ],
      "metadata": {
        "id": "Fa0ICfE7b5pR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "WQuEmWxX_P8X"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "import pprint  # To tidy up\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the Selenium WebDriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')  # Run headless to avoid UI pop-up\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "# Initialize the WebDriver\n",
        "driver = webdriver.Chrome(options=options)\n",
        "try:\n",
        "    # Target URL\n",
        "    url = \"https://www.rottentomatoes.com/browse/movies_at_home/critics:certified_fresh\"\n",
        "    # Navigate to the page\n",
        "    driver.get(url)\n",
        "\n",
        "    # Get page source and prepare it for parsing\n",
        "    page_source = driver.page_source\n",
        "    soup = BeautifulSoup(page_source, 'html.parser')\n",
        "    # Locate the container holding all the flex containers\n",
        "    grid_container = soup.find('div', class_='discovery-tiles')\n",
        "    # Find all flex-container elements within the grid container\n",
        "    flex_containers = grid_container.find_all('div', class_='flex-container')\n",
        "      # Initialize an empty list to store movie data dictionaries\n",
        "    movie_data = []\n",
        "\n",
        "    # Loop through each flex-container to extract the desired span elements\n",
        "    for flex in flex_containers:\n",
        "        name = flex.find('span', class_='p--small').text.strip()\n",
        "        year = flex.find('span', class_='smaller').text.strip()[10:]\n",
        "        score = flex.find('score-pairs-deprecated')['audiencescore']\n",
        "\n",
        "        # Store the movie data in a dictionary\n",
        "        data = {'Name': name, 'Year': year, 'Score': score}\n",
        "        movie_data.append(data)\n",
        "\n",
        "    # Create a DataFrame from the movie data list\n",
        "    df = pd.DataFrame(movie_data)\n",
        "\n",
        "\n",
        "    print(df)\n",
        "\n",
        "finally:\n",
        "    # Close the driver\n",
        "    driver.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_J1BcJ8_T3i",
        "outputId": "bfdc9a12-375e-4537-e2d6-70a0b516b399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      Name          Year Score\n",
            "0      Hundreds of Beavers  Apr 15, 2024    94\n",
            "1     The Zone of Interest  Feb 20, 2024    78\n",
            "2                 One Life   Apr 9, 2024    95\n",
            "3              Poor Things  Feb 27, 2024    79\n",
            "4        Anatomy of a Fall  Dec 22, 2023    90\n",
            "5     You'll Never Find Me  Mar 22, 2024    72\n",
            "6           Coup de Chance  Apr 12, 2024    79\n",
            "7            The Gentlemen  Mar 24, 2020    84\n",
            "8      All of Us Strangers  Feb 22, 2024    91\n",
            "9                    Wonka  Jan 30, 2024    91\n",
            "10          Dream Scenario  Dec 22, 2023    68\n",
            "11                    Dune  Oct 22, 2021    90\n",
            "12             Oppenheimer  Nov 21, 2023    91\n",
            "13       Godzilla vs. Kong  Mar 31, 2021    91\n",
            "14              Talk to Me  Sep 12, 2023    82\n",
            "15            Megan Leavey  Jul 10, 2017    82\n",
            "16                   Ennio   Apr 9, 2024   100\n",
            "17                   Split   Apr 5, 2017    79\n",
            "18            Perfect Days   Mar 5, 2024    89\n",
            "19             The Fallout  Jan 27, 2022    84\n",
            "20         Ordinary Angels  Mar 26, 2024    99\n",
            "21           The Iron Claw  Feb 13, 2024    94\n",
            "22  Leave the World Behind   Dec 8, 2023    35\n",
            "23              Stopmotion  Mar 15, 2024    50\n",
            "24        American Fiction   Feb 6, 2024    96\n",
            "25                       X  Apr 14, 2022    75\n",
            "26             Baby Driver  Jul 10, 2017    86\n",
            "27         Out of Darkness  Feb 27, 2024    55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üåü Exercise 4 : Scrape And Categorize News Articles From A JavaScript-Enabled News Site\n",
        "\n",
        "Visit a section of a news website (e.g., the Technology section of BBC News).\n",
        "\n",
        "Scrape news article titles and their publication dates.\n",
        "\n",
        "Categorize articles based on their publication month.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UkO2QfY-b-Vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "# Configure the Selenium WebDriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')  # Run headless to avoid UI pop-up\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "# Initialize the WebDriver\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        " # Target URL\n",
        "url = \"https://www.jpost.com/\"  # Replace with your URL\n",
        "# Navigate to the page\n",
        "driver.get(url)\n",
        "\n",
        "# Find the element by link text\n",
        "element = driver.find_element(By.LINK_TEXT, 'Kabbalah')\n",
        "\n",
        "# Click on the element\n",
        "element.click()\n",
        "try:\n",
        "    wait = WebDriverWait(driver, 10)\n",
        "\n",
        "    # Get page source and prepare it for parsing\n",
        "    page_source = driver.page_source\n",
        "    soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "    # Find the desired elements within the page\n",
        "    name_list = soup.find_all('h3', class_=\"itc-info-title\")\n",
        "    names = [name.text.strip() for name in name_list]\n",
        "\n",
        "    date_list = soup.find_all('span', class_=\"category-list-item-date\")\n",
        "    dates = [date.text.strip() for date in date_list]\n",
        "\n",
        "    print(names)\n",
        "    print(dates)\n",
        "finally:\n",
        "    # Close the driver\n",
        "    driver.quit()\n"
      ],
      "metadata": {
        "id": "jrmJckKo3dt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f522267-42a1-4a35-e618-601bfaa6689a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Shabbat - Rehearsal of The Return', 'The First Creation Of Adam: Can we make G-d work?', 'LIVE: Dr. Eduard Shyfrin discusses his upcoming book ‚ÄúThe Relativity of Death‚Äù', 'First creation of Adam: Does G-d use Ockham‚Äôs Razor?', 'The first creation of Adam  - Where, When, Why?', 'The Red Button of Adam - Part 2', 'The ‚ÄòRed Button‚Äô of Adam - Part 1', 'Eduard Shyfrin speaks at Jewish studies conference in Jerusalem', 'Part 6 - Relativity of Death: The origin of information', 'Part 8 - Relativity of Death: Life and death inside a Black Hole ‚Äì opinion']\n",
            "['31/05/2023', '04/04/2023', '15/03/2023', '02/02/2023', '12/12/2022', '02/10/2022', '30/08/2022', '09/08/2022', '26/06/2022', '26/06/2022']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "date_format = \"%d/%m/%Y\"\n",
        "\n",
        "articles_by_month = {\n",
        "    'January': [],\n",
        "    'February': [],\n",
        "    'March': [],\n",
        "    'April': [],\n",
        "    'May': [],\n",
        "    'June': [],\n",
        "    'July': [],\n",
        "    'August': [],\n",
        "    'September': [],\n",
        "    'October': [],\n",
        "    'November': [],\n",
        "    'December': []\n",
        "}\n",
        "\n",
        "for date, name in zip(dates, names):\n",
        "    # Convert the date string to a datetime object\n",
        "    date_object = datetime.strptime(date, date_format)\n",
        "\n",
        "    month_name = date_object.strftime('%B')\n",
        "\n",
        "    articles_by_month[month_name].append(name)\n",
        "\n",
        "\n",
        "for month, articles in articles_by_month.items():\n",
        "    print(month)\n",
        "    for article in articles:\n",
        "        print(\"- \" + article)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyOAyd2nw-9L",
        "outputId": "84d66bb0-13e6-4ede-f58f-f382fa3ce8fc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "January\n",
            "\n",
            "February\n",
            "- First creation of Adam: Does G-d use Ockham‚Äôs Razor?\n",
            "\n",
            "March\n",
            "- LIVE: Dr. Eduard Shyfrin discusses his upcoming book ‚ÄúThe Relativity of Death‚Äù\n",
            "\n",
            "April\n",
            "- The First Creation Of Adam: Can we make G-d work?\n",
            "\n",
            "May\n",
            "- Shabbat - Rehearsal of The Return\n",
            "\n",
            "June\n",
            "- Part 6 - Relativity of Death: The origin of information\n",
            "- Part 8 - Relativity of Death: Life and death inside a Black Hole ‚Äì opinion\n",
            "\n",
            "July\n",
            "\n",
            "August\n",
            "- The ‚ÄòRed Button‚Äô of Adam - Part 1\n",
            "- Eduard Shyfrin speaks at Jewish studies conference in Jerusalem\n",
            "\n",
            "September\n",
            "\n",
            "October\n",
            "- The Red Button of Adam - Part 2\n",
            "\n",
            "November\n",
            "\n",
            "December\n",
            "- The first creation of Adam  - Where, When, Why?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üåü Exercise 5 : Scrape And Analyze Weather Data From A JavaScript-Enabled Weather Website\n",
        "\n",
        "Visit a specific city‚Äôs weather forecast page on a weather website.\n",
        "\n",
        "Scrape weather forecast data including temperature, condition, and humidity.\n",
        "\n",
        "Analyze the data to find the average temperature and most common weather condition."
      ],
      "metadata": {
        "id": "14CUaUMfy6hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "# Configure the Selenium WebDriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')  # Run headless to avoid UI pop-up\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "# Initialize the WebDriver\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        " # Target URL\n",
        "url = \"https://weather.com/weather/today/l/5654c9edb068447e18017135241def26b619dac3428aa24e38e23a11d051991a\"\n",
        "# Navigate to the page\n",
        "driver.get(url)\n",
        "\n",
        "# Wait for the search bar element to be present\n",
        "search_bar = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, '10 Day')))\n",
        "element = driver.find_element(By.LINK_TEXT, '10 Day')\n",
        "\n",
        "element.click()\n",
        "\n",
        "\n",
        "try:\n",
        "    wait = WebDriverWait(driver, 10)\n",
        "\n",
        "    # Get page source and prepare it for parsing\n",
        "    page_source = driver.page_source\n",
        "    soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "    # Find the desired elements within the page\n",
        "    temperature_week = soup.find_all('span',class_=\"DetailsSummary--highTempValue--3PjlX\")\n",
        "    temperatures = [t.text.strip() for t in temperature_week]\n",
        "\n",
        "    condition_week = soup.find_all('span', class_=\"DetailsSummary--extendedData--307Ax\")\n",
        "    condition = [c.text.strip() for c in condition_week]\n",
        "\n",
        "    humidity_week = soup.find_all('span', {'data-testid': 'PercentageValue'})\n",
        "    humidity = [h.text.strip() for h in humidity_week][0:15]\n",
        "\n",
        "    print(temperatures)\n",
        "    print(condition)\n",
        "    print(humidity)\n",
        "finally:\n",
        "    # Close the driver\n",
        "    driver.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nvSi8lezGJ6",
        "outputId": "d61dca92-b724-426e-b6e2-9b3c9d5f91d5"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['--', '77¬∞', '74¬∞', '75¬∞', '75¬∞', '77¬∞', '86¬∞', '93¬∞', '86¬∞', '81¬∞', '79¬∞', '79¬∞', '79¬∞', '79¬∞', '80¬∞']\n",
            "['Mostly Clear', 'Sunny', 'Partly Cloudy', 'Mostly Sunny', 'Mostly Sunny', 'Sunny', 'Mostly Sunny', 'Partly Cloudy', 'Mostly Cloudy', 'Partly Cloudy', 'Mostly Sunny', 'Mostly Sunny', 'Sunny', 'Partly Cloudy', 'Partly Cloudy']\n",
            "['0%', '38%', '4%', '4%', '63%', '9%', '82%', '16%', '16%', '67%', '8%', '79%', '6%', '6%', '63%']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_list = []\n",
        "for item in temperatures:\n",
        "\n",
        "    cleaned_item = ''.join(filter(str.isdigit, item))\n",
        "    if cleaned_item:\n",
        "        int_list.append(int(cleaned_item))\n",
        "    else:\n",
        "        int_list.append(None)\n",
        "print(int_list)"
      ],
      "metadata": {
        "id": "Lrqv-xncL9-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_list_humidity = []\n",
        "for item in humidity:\n",
        "\n",
        "    cleaned_item = ''.join(filter(str.isdigit, item))\n",
        "    if cleaned_item:\n",
        "        int_list_humidity.append(int(cleaned_item))\n",
        "    else:\n",
        "        int_list_humidity.append(None)\n",
        "print(int_list_humidity)"
      ],
      "metadata": {
        "id": "b2guNgNKMRwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'Temperature':int_list,\n",
        "        'Condition': condition,\n",
        "        'Humidity': int_list_humidity\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df\n",
        "\n",
        "weather_counts = Counter(condition)\n",
        "most_common_weather = weather_counts.most_common(1)\n",
        "\n",
        "\n",
        "# Print the result\n",
        "print('The average temperature in Tel Aviv for the following 10 days is ', df['Temperature'].mean(), ' F')\n",
        "print('The the most common weather condition for in Tel Aviv the following 10 days is ',most_common_weather[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj1Mm28GHeZh",
        "outputId": "e76df98c-45bc-4dce-cd86-06efe4d626bc"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average temperature in Tel Aviv for the following 10 days is  80.0  F\n",
            "The the most common weather condition for in Tel Aviv the following 10 days is  Partly Cloudy\n"
          ]
        }
      ]
    }
  ]
}
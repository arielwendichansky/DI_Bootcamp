{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl4Va2NSzXHVaaeAJgUhs8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arielwendichansky/DI_Bootcamp/blob/master/Week7/Day2/Exercise_XP/Exercise_XP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install selenium\n"
      ],
      "metadata": {
        "id": "ES8GPYSI_cJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸŒŸ Exercise 3 : Scrape Dynamic Content From Rotten Tomatoes\n",
        "Task:\n",
        "Use Selenium to navigate to the Rotten Tomatoes Certified Fresh Movies page.\n",
        "Extract the HTML content after itâ€™s fully loaded.\n",
        "Use BeautifulSoup to parse and extract the movie titles, scores, and release dates.\n",
        "Instructions\n",
        "Set up Selenium WebDriver and navigate to the Rotten Tomatoes page.\n",
        "Extract the HTML content using driver.page_source.\n",
        "Parse the HTML with BeautifulSoup.\n",
        "Find and extract the desired movie information.\n",
        "Print the extracted data"
      ],
      "metadata": {
        "id": "Fa0ICfE7b5pR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WQuEmWxX_P8X"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "import pprint  # To tidy up\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the Selenium WebDriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')  # Run headless to avoid UI pop-up\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "# Initialize the WebDriver\n",
        "driver = webdriver.Chrome(options=options)\n",
        "try:\n",
        "    # Target URL\n",
        "    url = \"https://www.rottentomatoes.com/browse/movies_at_home/critics:certified_fresh\"\n",
        "    # Navigate to the page\n",
        "    driver.get(url)\n",
        "\n",
        "    # Get page source and prepare it for parsing\n",
        "    page_source = driver.page_source\n",
        "    soup = BeautifulSoup(page_source, 'html.parser')\n",
        "    # Locate the container holding all the flex containers\n",
        "    grid_container = soup.find('div', class_='discovery-tiles')\n",
        "    # Find all flex-container elements within the grid container\n",
        "    flex_containers = grid_container.find_all('div', class_='flex-container')\n",
        "      # Initialize an empty list to store movie data dictionaries\n",
        "    movie_data = []\n",
        "\n",
        "    # Loop through each flex-container to extract the desired span elements\n",
        "    for flex in flex_containers:\n",
        "        name = flex.find('span', class_='p--small').text.strip()\n",
        "        year = flex.find('span', class_='smaller').text.strip()[10:]\n",
        "        score = flex.find('score-pairs-deprecated')['audiencescore']\n",
        "\n",
        "        # Store the movie data in a dictionary\n",
        "        data = {'Name': name, 'Year': year, 'Score': score}\n",
        "        movie_data.append(data)\n",
        "\n",
        "    # Create a DataFrame from the movie data list\n",
        "    df = pd.DataFrame(movie_data)\n",
        "\n",
        "\n",
        "    print(df)\n",
        "\n",
        "finally:\n",
        "    # Close the driver\n",
        "    driver.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_J1BcJ8_T3i",
        "outputId": "bfdc9a12-375e-4537-e2d6-70a0b516b399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      Name          Year Score\n",
            "0      Hundreds of Beavers  Apr 15, 2024    94\n",
            "1     The Zone of Interest  Feb 20, 2024    78\n",
            "2                 One Life   Apr 9, 2024    95\n",
            "3              Poor Things  Feb 27, 2024    79\n",
            "4        Anatomy of a Fall  Dec 22, 2023    90\n",
            "5     You'll Never Find Me  Mar 22, 2024    72\n",
            "6           Coup de Chance  Apr 12, 2024    79\n",
            "7            The Gentlemen  Mar 24, 2020    84\n",
            "8      All of Us Strangers  Feb 22, 2024    91\n",
            "9                    Wonka  Jan 30, 2024    91\n",
            "10          Dream Scenario  Dec 22, 2023    68\n",
            "11                    Dune  Oct 22, 2021    90\n",
            "12             Oppenheimer  Nov 21, 2023    91\n",
            "13       Godzilla vs. Kong  Mar 31, 2021    91\n",
            "14              Talk to Me  Sep 12, 2023    82\n",
            "15            Megan Leavey  Jul 10, 2017    82\n",
            "16                   Ennio   Apr 9, 2024   100\n",
            "17                   Split   Apr 5, 2017    79\n",
            "18            Perfect Days   Mar 5, 2024    89\n",
            "19             The Fallout  Jan 27, 2022    84\n",
            "20         Ordinary Angels  Mar 26, 2024    99\n",
            "21           The Iron Claw  Feb 13, 2024    94\n",
            "22  Leave the World Behind   Dec 8, 2023    35\n",
            "23              Stopmotion  Mar 15, 2024    50\n",
            "24        American Fiction   Feb 6, 2024    96\n",
            "25                       X  Apr 14, 2022    75\n",
            "26             Baby Driver  Jul 10, 2017    86\n",
            "27         Out of Darkness  Feb 27, 2024    55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸŒŸ Exercise 4 : Scrape And Categorize News Articles From A JavaScript-Enabled News Site\n",
        "Task:\n",
        "Visit a section of a news website (e.g., the Technology section of BBC News).\n",
        "\n",
        "Scrape news article titles and their publication dates.\n",
        "\n",
        "Categorize articles based on their publication month.\n",
        "\n",
        "Instructions:\n",
        "\n",
        "Use Selenium to navigate to a specific news section on the website.\n",
        "\n",
        "Extract and parse the HTML content that is dynamically loaded via JavaScript.\n",
        "\n",
        "Using BeautifulSoup, extract news article titles and publication dates.\n",
        "\n",
        "Categorize articles by their publication month (e.g., â€˜Januaryâ€™, â€˜Februaryâ€™, etc.).\n",
        "\n",
        "Print the categorized lists of articles.\n"
      ],
      "metadata": {
        "id": "UkO2QfY-b-Vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "# Configure the Selenium WebDriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')  # Run headless to avoid UI pop-up\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "# Initialize the WebDriver\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        " # Target URL\n",
        "url = \"https://www.bbc.com/news\"  # Replace with your URL\n",
        "# Navigate to the page\n",
        "driver.get(url)\n",
        "\n",
        "# Find the element by link text\n",
        "element = driver.find_element(By.LINK_TEXT, 'Travel')\n",
        "\n",
        "# Click on the element\n",
        "element.click()\n",
        "try:\n",
        "    wait = WebDriverWait(driver, 10)\n",
        "    # Wait for the element to be present in the DOM\n",
        "    # element = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'sc-4fedabc7-3 bHIBya')))\n",
        "\n",
        "    # Get page source and prepare it for parsing\n",
        "    page_source = driver.page_source\n",
        "    soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "      # Find the desired elements within the page\n",
        "    name_list = soup.find_all('h2', class_=\"sc-4fedabc7-3 zTZri\")\n",
        "    names = [name.text.strip() for name in name_list]\n",
        "\n",
        "    date_list = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/article//span[@data-testid=\"card-metadata-lastupdated\"]')\n",
        "    print(date_list)\n",
        "    dates = [date.text.strip() for date in date_list]\n",
        "\n",
        "    print(names)\n",
        "    print(dates)\n",
        "finally:\n",
        "    # Close the driver\n",
        "    driver.quit()\n"
      ],
      "metadata": {
        "id": "jrmJckKo3dt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "881f4754-5610-4bb7-8a8e-8a2ceff3d617"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[\"Canada's remote bike-in mountain lodge\", 'The simple Costa Rican secrets to longevity', \"Easter tourist attractions see trade 'down by 25%'\", 'EasyJet suspends flights to Israel until October', 'Rail attraction set for summer holiday opening', 'Church opens doors to paying holiday guests', 'What are my rights if my flight is cancelled or delayed?', \"What it's like to ski in the path of totality\", 'How to photograph the total solar eclipse', \"How a fictitious 'sea' became a top attraction\", 'Nine iconic Paris sites to watch the Olympics', \"Mexico's controversial new 'superhighway'\", 'The female explorer who transformed travel', 'Eight of the best bagels in New York City', \"A geographer's guide to London's green spaces\", \"A chef's guide to the best carbonara in Rome\", 'Five under-the-radar eats in Los Angeles', 'Where to see spring tulips in the Netherlands', \"An expert's guide to the best cheese in Paris\", 'Six of the best comedy clubs in Toronto', \"A former F1 engineer's weekend guide to Melbourne\", 'The Japanese town where you can sleep in a castle', \"Turkey's 'time-warp' islands where cars are banned\", \"Why India's wildly remote islands are trending\", 'The industrial English city with more trees than people', \"Thailand's cooling rice dish to beat the heat\", 'The most beautiful cake for Ramadan', \"China's sweet dumpling to remember the dead\", \"The 'calorie-bomb' avocado smoothie for Ramadan\"]\n",
            "[]\n"
          ]
        }
      ]
    }
  ]
}